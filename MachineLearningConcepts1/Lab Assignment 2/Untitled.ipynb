{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d832728a-2913-4a00-a386-89ecf87b4b3c",
   "metadata": {},
   "source": [
    "# Major Assignment – 2 (Chapter 3 – 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb862cc-de74-407d-8e9f-751a6fece164",
   "metadata": {},
   "source": [
    "## Part B – Lab Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e441c8b5-701b-4347-afb9-73708e3a2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 10.710864418838371\n",
      "R2= 0.790150038676035\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q1. An automobile company wants to predict a car’s mpg value from its physical attributes.\n",
    "Tasks:\n",
    "(a) Load the dataset auto_mpg.csv and remove missing values.\n",
    "(b) Identify predictor and target variables.\n",
    "(c) Perform data splitting (80% train, 20% test).\n",
    "(d) Fit a Linear Regression model and predict test outcomes.\n",
    "(e) Evaluate the model using Mean Squared Error and R² score.\n",
    "(f) Discuss: If the R² score = 0.85, what does it imply about model performance?\"\"\"\n",
    "\n",
    "\n",
    "# (a)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"auto_mpg.csv\") \n",
    "df = df.dropna ()\n",
    "df = df.drop(columns=[\"car_name\"])\n",
    "# (b)\n",
    "X = df.drop(\"mpg\", axis=1)\n",
    "y = df [\"mpg\"]\n",
    "# (c)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "# (d)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()\n",
    "model.fit(X_train, y_train) \n",
    "y_pred=model.predict(X_test)\n",
    "# (e)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "r2=r2_score (y_test, y_pred)\n",
    "print(\"MSE=\", mse)\n",
    "print(\"R2=\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acd7bc5-c724-4613-b07c-e5dd176f3541",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1738826462.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    boot resample (X, n_samples=100, replace=True, random_state=42)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q2. Exploring random sampling methods to estimate model uncertainty.\n",
    "Tasks:\n",
    "(a) From the btissue.csv data, extract only the feature columns (excluding labels).\n",
    "(b) Using the resample() method, create a bootstrap sample of 100 observations.\n",
    "(c) Show the first 10 rows of the sample and identify if any rows are repeated.\"\"\"\n",
    "\n",
    "\n",
    "# (a)\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "df = pd.read_csv(\"btissue.csv\") \n",
    "X = df.drop(columns=[\"class\"])\n",
    "# (b)\n",
    "boot resample (X, n_samples=100, replace=True, random_state=42)\n",
    "# (c)\n",
    "print(boot.head (10))\n",
    "print(boot.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bac367-c595-4cd9-9112-7cb5971dc373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q3. Instead of relying on a single train–test split, you want to check how consistent your\n",
    "model is.\n",
    "Tasks:\n",
    "(a) Using the btissue.csv dataset, implement 5-fold cross-validation.\n",
    "(b) For each fold, print the train/test indices and record how many samples are used for\n",
    "training vs testing.\n",
    "(c) Visualize or summarize how different folds cover the entire dataset without overlap.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d8b69-87e7-4df8-930b-506b52cfcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q4. Testing two validation techniques to measure model generalization.\n",
    "Tasks:\n",
    "(a) Use the btissue.csv dataset and a Decision Tree Classifier.\n",
    "(b) Evaluate model performance using:\n",
    "i) Holdout (80/20 split)\n",
    "ii) 5-Fold Cross-Validation\n",
    "(c) Compare the accuracy results from both methods.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575bd21c-2e6b-41fd-89e9-467a82113a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q5. Feature Creation from Structured Data\n",
    "(a) Using a dataset containing columns like Age, Income, and Spending Score, construct\n",
    "new derived features such as Age Group, Income-to-Spending Ratio, and Normalized\n",
    "Spending.\n",
    "(b) Plot and analyze how the new features correlate with the target variable.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833e5f0-4414-4ef7-a0b6-46ddbb0e89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q6. Load the Iris dataset and select a subset of features manually using the .iloc function.\n",
    "Train a simple Decision Tree Classifier using only the selected subset of features and\n",
    "compare its performance with the model trained using all features.\n",
    "Tasks:\n",
    "(a) Load the Iris dataset from sklearn.datasets.\n",
    "(b) Create a DataFrame and display the first few rows.\n",
    "(c) Train a Decision Tree Classifier using all features and record the accuracy.\n",
    "(d) Select a subset of columns (for example, the first two features: sepal length and sepal\n",
    "width) using .iloc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4b545-fb45-43b6-aa56-54a3cd8d8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q7. Load the Iris dataset and apply Principal Component Analysis (PCA) to reduce its four\n",
    "numerical features (sepal length, sepal width, petal length, petal width) into two principal\n",
    "components. Visualize the transformed data in a 2D scatter plot to observe how the classes\n",
    "(Setosa, Versicolor, Virginica) are separated in the reduced feature space. Additionally,\n",
    "display the explained variance ratio for each component.\n",
    "Tasks:\n",
    "(a) Load the Iris dataset using sklearn.datasets.\n",
    "(b) Perform PCA to reduce the dataset to two components.\n",
    "(c) Create a new DataFrame containing the two principal components and target labels.\n",
    "(d) Plot the two components using a scatter plot with different colors for each class.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926109c-a976-4261-8025-04270890722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q8. Create a dataset containing employee information, including Department, Job Role, and\n",
    "Marital Status. Convert all categorical columns into numeric form so that the dataset can be\n",
    "used effectively for training machine learning models. Use appropriate encoding techniques\n",
    "such as Label Encoding and One-Hot Encoding.\n",
    "Tasks:\n",
    "(a) Create a DataFrame with the following columns and sample data:\n",
    "Department (e.g., HR, IT, Finance)\n",
    "Job_Role (e.g., Manager, Analyst, Clerk)\n",
    "Marital_Status (e.g., Single, Married, Divorced)\n",
    "(b) Display the original dataset.\n",
    "(c) Encode categorical columns using:\n",
    "Label Encoding for ordered or binary categories.\n",
    "One-Hot Encoding for nominal categories.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
